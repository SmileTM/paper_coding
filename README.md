# Paper Coding [TF2.0]

1. NMT_with_Attenion　

    [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025v5)　

    [NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE](https://arxiv.org/pdf/1409.0473.pdf)

    **[[code]](https://github.com/SmileTM/paper_coding/tree/master/NMT_attention)**
    
2. Transformer_block

    [Attention Is All You Need](http://arxiv.org/abs/1706.03762)
    
    **[[code]](https://github.com/SmileTM/paper_coding/tree/master/Transformer)**
 
3. Bert

    [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](http://arxiv.org/abs/1810.04805)
    
    **[[code]](https://github.com/SmileTM/paper_coding/tree/master/Bert)**